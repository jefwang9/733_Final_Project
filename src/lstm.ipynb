{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pandas import DataFrame\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from torch import nn\n",
    "import torch\n",
    "import numpy as np\n",
    "from torch.autograd import Variable "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Unnamed: 0', 'Departure', 'Return', 'Bike', 'Departure station',\n",
      "       'Return station', 'Membership type', 'Covered distance (m)',\n",
      "       'Duration (sec.)', 'Departure battery voltage (mV)',\n",
      "       'Return battery voltage (mV)', 'Departure temperature (C)',\n",
      "       'Return temperature (C)', 'Stopover duration (sec.)',\n",
      "       'Number of stopovers', 'postal_code_x', 'Departure lat',\n",
      "       'Departure long', 'postal_code_y', 'Return lat', 'Return long'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "mobi_data = pd.read_csv(\"../data/Mobi_System_Data_2020.csv\", compression='zip').dropna()\n",
    "geo_data = pd.read_csv('../data/geocodings.csv',index_col=0)\n",
    "data = mobi_data.merge(geo_data.rename({'lat':'Departure lat','long':'Departure long'},axis=1),left_on='Departure station',right_on='address').drop('address',axis=1)\n",
    "data = data.merge(geo_data.rename({'lat':'Return lat','long':'Return long'},axis=1),left_on='Return station',right_on='address').drop('address',axis=1)\n",
    "data.shape\n",
    "# data = data.loc[data[\"Departure postal code\"].str.startswith(\"V6\")]\n",
    "print(data.columns)\n",
    "data[\"time\"] = pd.to_datetime(data[\"Departure\"], format=\"%Y-%m-%d %H:%M:%S\")\n",
    "data[\"hour\"] = data[\"time\"].dt.hour\n",
    "data[\"day\"] = data[\"time\"].dt.day\n",
    "data[\"month\"] = data[\"time\"].dt.month\n",
    "data[\"year\"] = data[\"time\"].dt.year\n",
    "\n",
    "# train_data = data[[\"year\", \"month\", \"day\", \"hour\", \"Departure lat\", \"Departure long\"]]\n",
    "features_departure = [\"month\", \"day\", \"hour\", \"Departure lat\", \"Departure long\"]\n",
    "counts_data = data.groupby([\"month\", \"day\", \"hour\", \"Departure lat\", \"Departure long\", \"Departure station\"]).size().reset_index(name='counts')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "221\n",
      "            month       day      hour  Departure lat  Departure long  \\\n",
      "0        0.083333  0.032258  0.000000       0.693601        0.000627   \n",
      "1        0.083333  0.032258  0.043478       0.693601        0.000627   \n",
      "2        0.083333  0.032258  0.086957       0.693601        0.000627   \n",
      "3        0.083333  0.032258  0.130435       0.693601        0.000627   \n",
      "4        0.083333  0.032258  0.173913       0.693601        0.000627   \n",
      "...           ...       ...       ...            ...             ...   \n",
      "1935955  1.000000  0.967742  0.826087       0.284948        0.841722   \n",
      "1935956  1.000000  0.967742  0.869565       0.284948        0.841722   \n",
      "1935957  1.000000  0.967742  0.913043       0.284948        0.841722   \n",
      "1935958  1.000000  0.967742  0.956522       0.284948        0.841722   \n",
      "1935959  1.000000  0.967742  1.000000       0.284948        0.841722   \n",
      "\n",
      "                                Departure station  counts  \n",
      "0        0099 Vancouver Art Gallery - North Plaza     1.0  \n",
      "1        0099 Vancouver Art Gallery - North Plaza     0.0  \n",
      "2        0099 Vancouver Art Gallery - North Plaza     2.0  \n",
      "3        0099 Vancouver Art Gallery - North Plaza     1.0  \n",
      "4        0099 Vancouver Art Gallery - North Plaza     0.0  \n",
      "...                                           ...     ...  \n",
      "1935955             0985 Quebec Yard - To Service     0.0  \n",
      "1935956             0985 Quebec Yard - To Service     0.0  \n",
      "1935957             0985 Quebec Yard - To Service     0.0  \n",
      "1935958             0985 Quebec Yard - To Service     0.0  \n",
      "1935959             0985 Quebec Yard - To Service     0.0  \n",
      "\n",
      "[1935960 rows x 7 columns]\n"
     ]
    }
   ],
   "source": [
    "stations = data[[\"Departure lat\", \"Departure long\", \"Departure station\"]].drop_duplicates()\n",
    "max_lat, min_lat = stations[\"Departure lat\"].max(), stations[\"Departure lat\"].min()\n",
    "max_long, min_long = stations[\"Departure long\"].max(), stations[\"Departure long\"].min()\n",
    "batch = stations.shape[0]\n",
    "print(batch)\n",
    "predict_data_departure = pd.DataFrame(data={\n",
    "    \"month\": [], \n",
    "    \"day\": [], \n",
    "    \"hour\": [], \n",
    "    \"Departure lat\": [],\n",
    "    \"Departure long\": []})\n",
    "for row in stations.iterrows():\n",
    "    time = pd.date_range('2020-01-01', periods=8760, freq='H')\n",
    "\n",
    "    station_data = pd.DataFrame(data={\"time\": time})\n",
    "    station_data[\"hour\"] = station_data[\"time\"].dt.hour\n",
    "    station_data[\"day\"] = station_data[\"time\"].dt.day\n",
    "    station_data[\"month\"] = station_data[\"time\"].dt.month\n",
    "    station_data[\"Departure lat\"] = (row[1][\"Departure lat\"] - min_lat) / (max_lat - min_lat)\n",
    "    station_data[\"Departure long\"] = (row[1][\"Departure long\"] - min_long) / (max_long - min_long)\n",
    "    station_data[\"Departure station\"] = row[1][\"Departure station\"]\n",
    "    station_data = station_data.drop(columns=[\"time\"])\n",
    "    \n",
    "    predict_data_departure = pd.concat([predict_data_departure, station_data])\n",
    "\n",
    "train_data = predict_data_departure.merge(counts_data[[\"month\", \"day\", \"hour\", \"Departure station\", \"counts\"]], how=\"left\", left_on=[\"month\", \"day\", \"hour\", \"Departure station\"], right_on=[\"month\", \"day\", \"hour\", \"Departure station\"])\n",
    "train_data[\"counts\"] = train_data[\"counts\"].fillna(0)\n",
    "train_data[\"month\"] = train_data[\"month\"] / 12\n",
    "train_data[\"day\"] = train_data[\"day\"] / 31\n",
    "train_data[\"hour\"] = train_data[\"hour\"] / 23\n",
    "# train_data = train_data.sort_values(by=\"Departure station\")\n",
    "print(train_data)\n",
    "x = train_data[features_departure]\n",
    "y = train_data[\"counts\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTM(nn.Module):\n",
    "    def __init__(self, input_size=5, hidden_layer_size=5, output_size=1):\n",
    "        super().__init__()\n",
    "        self.hidden_layer_size = hidden_layer_size\n",
    "\n",
    "        self.lstm = nn.LSTM(input_size, hidden_layer_size, batch_first=True)\n",
    "\n",
    "        self.linear = nn.Linear(hidden_layer_size, output_size)\n",
    "\n",
    "        self.hidden_cell = (torch.zeros(1, batch, self.hidden_layer_size),\n",
    "                            torch.zeros(1, batch, self.hidden_layer_size))\n",
    "\n",
    "    def forward(self, input_seq):\n",
    "        lstm_out, self.hidden_cell = self.lstm(input_seq, self.hidden_cell)\n",
    "        predictions = self.linear(lstm_out)\n",
    "        return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.7678512334823608\n",
      "Loss: 0.7913770079612732\n",
      "Loss: 0.7585370540618896\n",
      "Loss: 0.7612772583961487\n",
      "Loss: 0.7645926475524902\n",
      "Loss: 0.7616039514541626\n",
      "Loss: 0.7573513388633728\n",
      "Loss: 0.7548993229866028\n",
      "Loss: 0.7549518346786499\n",
      "Loss: 0.7564924359321594\n",
      "Loss: 0.7578408718109131\n",
      "Loss: 0.7579511404037476\n",
      "Loss: 0.7569201588630676\n",
      "Loss: 0.7555580735206604\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_15276\\1464220976.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     13\u001b[0m     \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_x\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m     \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_y\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m     \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     16\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Loss:'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m     \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\anaconda\\envs\\cmpt733\\lib\\site-packages\\torch\\_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    361\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    362\u001b[0m                 inputs=inputs)\n\u001b[1;32m--> 363\u001b[1;33m         \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    364\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    365\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\anaconda\\envs\\cmpt733\\lib\\site-packages\\torch\\autograd\\__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    173\u001b[0m     Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0;32m    174\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 175\u001b[1;33m         allow_unreachable=True, accumulate_grad=True)  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[0;32m    176\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    177\u001b[0m def grad(\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train_x = torch.tensor(x.to_numpy()).float()\n",
    "train_y = torch.tensor(y.to_numpy()).float()\n",
    "l = train_x.shape[0]\n",
    "train_x = train_x.reshape((batch, int(l / batch), 5))\n",
    "train_y = train_y.reshape((batch, int(l / batch), 1))\n",
    "\n",
    "model = LSTM()\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-1)\n",
    "for e in range(20):\n",
    "    model.zero_grad()\n",
    "    model.hidden_cell = (torch.zeros(1, batch, model.hidden_layer_size), torch.zeros(1, batch, model.hidden_layer_size))\n",
    "    out = model(train_x)\n",
    "    loss = criterion(out, train_y)\n",
    "    loss.backward()\n",
    "    print('Loss:',loss.item())\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                  counts\n",
      "Departure station                                       \n",
      "0995 Workshop - On Deck                      1713.635254\n",
      "0981 Workshop - Service Complete             1761.683228\n",
      "0245 Woodland & 10th                         1825.209595\n",
      "0215 Princess & Union                        1837.238159\n",
      "0281 Windsor & 14th                          1867.220703\n",
      "...                                                  ...\n",
      "0209 Stanley Park - Information Booth        2558.562744\n",
      "0105 Stanley Park - Totem Poles              2558.592773\n",
      "0101 Stanley Park - Vancouver Aquarium       2558.706543\n",
      "0103 Stanley Park - Third Beach Parking Lot  2559.119141\n",
      "0206 8th & Scotia                            2735.822754\n",
      "\n",
      "[221 rows x 1 columns]\n",
      "                                        counts\n",
      "Departure station                             \n",
      "0995 Workshop - On Deck                      2\n",
      "0985 Yard - Long Term Storage                2\n",
      "0986 Quebec Yard - Serviced                  5\n",
      "0129 Richards & Robson - TEMP REMOVED       39\n",
      "0165 Columbia & 4th - TEMP REMOVED          40\n",
      "...                                        ...\n",
      "0011 Ontario & Seawall                    8707\n",
      "0102 Stanley Park - Second Beach North    8979\n",
      "0209 Stanley Park - Information Booth     9988\n",
      "0066 Anderson & 2nd                      10058\n",
      "0028 Davie & Beach                       10881\n",
      "\n",
      "[221 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "predict_data_departure = pd.DataFrame(data={\n",
    "    \"month\": [], \n",
    "    \"day\": [], \n",
    "    \"hour\": [], \n",
    "    \"Departure lat\": [],\n",
    "    \"Departure long\": [],})\n",
    "for row in stations.iterrows():\n",
    "    time = pd.date_range('2022-01-01', periods=8760, freq='H')\n",
    "\n",
    "    station_data = pd.DataFrame(data={\"time\": time})\n",
    "    station_data[\"hour\"] = station_data[\"time\"].dt.hour / 23\n",
    "    station_data[\"day\"] = station_data[\"time\"].dt.day / 31\n",
    "    station_data[\"month\"] = station_data[\"time\"].dt.month / 12\n",
    "    station_data[\"Departure lat\"] = (row[1][\"Departure lat\"] - min_lat) / (max_lat - min_lat)\n",
    "    station_data[\"Departure long\"] = (row[1][\"Departure long\"] - min_long) / (max_long - min_long)\n",
    "    station_data[\"Departure station\"] = row[1][\"Departure station\"]\n",
    "    station_data = station_data.drop(columns=[\"time\"])\n",
    "    \n",
    "    predict_data_departure = pd.concat([predict_data_departure, station_data])\n",
    "predict_x = predict_data_departure[features_departure].to_numpy()\n",
    "tensor_x = torch.tensor(predict_x).float()\n",
    "tensor_x = tensor_x.reshape((batch, int(tensor_x.shape[0] / batch), 5))\n",
    "with torch.no_grad():\n",
    "        model.hidden = (torch.zeros(1, batch, model.hidden_layer_size), torch.zeros(1, batch, model.hidden_layer_size))\n",
    "        output = model(tensor_x)\n",
    "predict_data_departure[\"counts\"] = torch.flatten(output)\n",
    "predict_data_departure = predict_data_departure[[\"Departure station\", \"counts\"]].groupby(\"Departure station\").sum().sort_values(\"counts\")\n",
    "print(predict_data_departure)\n",
    "test = counts_data[[\"Departure station\", \"counts\"]].groupby(\"Departure station\").sum().sort_values(\"counts\")\n",
    "print(test)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "6201843772fd9857aa519d927ec692354182860add5b8d93783d514dd2c767d8"
  },
  "kernelspec": {
   "display_name": "Python 3.7.11 ('CMPT733A1')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
